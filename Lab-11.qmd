---
title: 'Lab 11'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment = NA)
```

## Two Factor Between Subject ANOVA

Recall the way that the ANOVA is formatted:

```{r}
# Create the IV
groups = rep(c("Control","Treatment 1", "Treatment 2"), each = 20)

# Create the DV
score =c(rnorm(20,10),rnorm(20,15),rnorm(20,22))

# Combine
onefact <- data.frame(groups,score)
```

We have three independent variables, or conditions, **control**, **treatment 1** and **treatment 2**. We have one dependent variable, some idea of "**score**".

The ANOVA is analyzed through the use of the `aov` function. Remember to save the analysis as a model so you can use it later if you need to do any post-hoc tests/unplanned comparisons.

```{r,echo=FALSE}
# Save to model
onefact.mod <- aov(score~groups, data=onefact)

# Add to model
summary(onefact.mod)
```

This produces:

-   a sum of squares and mean squares for the between subjects factor, `groups`.

-   It also produces a sum of squares and mean squares for the within subjects factor, also called the residuals, or the error.

-   From this we get one F-value.

### What if we have two IV's?

The current design will not help us too much so we need to move on to another design, the two factor between subjects ANOVA.

The set-up is mostly the same:

```{r}
# Create sex variable 
Sex = rep(c("Male","Female"),each = 30)

Diet = rep(c("Diet 1", "Diet 2"), 30)

Count = c(rnorm(30,28,2),rnorm(30,35,2))

twofact.df <- data.frame(Sex,Diet,Count)

twofact.df
```

We can see that there are two levels of the independent variable `Sex` and two levels of the independent variable `Diet` and one dependent variable, `count`.

From this we will generate four sums of squares and four mean squares.

-   Sum of Squares for Factor A

-   Sum of Squares for Factor B

-   Sum of Squares for the *interaction* between A and B

-   Sum of Squares within, or Error, or residual.

Analyzing the data just uses one more term:

```{r}
# Create the model
twofact.mod<-aov(Count~Sex*Diet,data = twofact.df)

# Calculate summary statistics
summary(twofact.mod)
```

Okay, so we have the anova table, but what do these results look like? From this data, we have three possibilities:

-   There is a main effect of Sex

-   There is a main effect of Diet

-   There is an *interaction* on Sex and Diet

In order to plot these relationships we use `interaction.plot`.

```{r}
# Plot the interaction
interaction.plot(twofact.df$Sex,twofact.df$Diet, twofact.df$Count,
                 type = "o",
                 legend = TRUE,
                 xlab = "Sex",
                 ylab = "Mean of Count",
                 trace.label = "Diet Type")
```

### Visualize No Interaction

```{r}
# Create DV with variable means (15,20,30,40)
scored=rnorm(80,c(15,20,15,20))

# Create IV with two levels
iv1 = rep(c("Level 1","Level 2"),each=2,20)

# Create IV with two levels
iv2 = rep(c("Group 1","Group 2"),each=1,40)

# Combine
df <- data.frame(iv1,iv2,scored)

# Create Model and plot
summary(aov(scored~iv1*iv2,data = df))
interaction.plot(iv1,iv2,scored)
```

## Two Factor Within Subjects ANOVA

In a Two Factor Between Subjects ANOVA, a particular participant is only ever in one condition or group or treatment level.

In a Two Factor Within Subjects ANOVA, a particular participant is in *each* condition or group or treatment level.

Setting this data up uses the same principles as we have learned before.

The one major difference in the set-up of the data is that there is now a variable of the subject itself.

When we had a between subjects design, each participant was unique, with a within design, each participant experiences every aspect of the experiment so it is reasonable that they may have an effect on the experiment itself.

Here is a sample dataset:

```{r}
# For reproduction
set.seed(1234)

# Create subject vector
subject <- rep(1:10,4)

# Create IV
groups <- rep(c("pre","post","post 1", "post 2"),each = 10)

# Create DV
score <- rnorm(40,c(20,30,40,70))

# Create dataframe
within_anova <- data.frame(subject,groups,score)
within_anova
```

It would be helpful if we could see the means of each group, and plot those means.

For this, we will use a new function called `tappy`. This applies a specified function to whatever variables you provide in the arguments.

To get the means:

```{r}
within_means <- tapply(within_anova$score,within_anova$groups,mean)
within_means
```

To get the standard deviations:

```{r}
within_sd <- tapply(within_anova$score,within_anova$groups,sd)
within_sd
```

For now, it will only be important to use `tapply` in order to get the means.

Here is how we will plot the means:

```{r}

plot(within_means,
     pch=19,
     xlab = "Treatments",
     ylab = "Survey Score",
     main = "Means of Survey Score by Treatment")
```

Performing the ANOVA requires two new terms: `Error` and the `Subject` factor.

The model that the ANOVA should resemble looks like this:

`aov(DV ~ IV+ Error(Subjects))`

From here it is important to note that your IV **must** be a factor.

-   With this in mind, you should run the function `levels(Grouping Variable`) or `factor(Grouping Variable`.)

-   If the first function returns `NULL`, use the second function.

Putting all of this together gives us the following:

```{r}

within_anova.mod <- aov(score ~ groups + Error(subject))

summary(within_anova.mod)
```

When reporting these findings, you will ignore the subject variable and report the F-value for the grouping variable.

This particular finding should be reported as follows:

> The results of a one-factor within subjects ANOVA, *F(3,35) = .303, p \>.05,* revealed that there does not appear to be any effect of treatment on survey score.

## Effect Sizes

Most times you will want to report effect sizes for your experiment. Effect sizes help to tell you how much of your effect is *due* to your manipulation.

In this example, there does not appear to be an effect at all, but we will compute an effect size anyways.

We will be using the $\omega^2$ (omega-squared) effect size estimate.

The formula is as follows:

$$\omega^2 = \frac{SS_B-(k-1)(MS_W)}{SS_T-MS_W}$$

or

$$\omega^2 = \frac{SS_{Effect}-(k-1)(MS_{Within})}{SS_{Total}-MS_{Within}}$$

There is no `R` function that reports $\omega^2$, so we will do this by hand.

$\omega^2 = \frac{355-(4-1)(390.4)}{14020-390.4}$

$\omega^2 = -.059$

This effect size is negative because our effect was not significant, but it is still important for you to see how to get these numbers!
